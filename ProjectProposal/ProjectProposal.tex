\documentclass[12pt]{article}
\usepackage[margin=0.8in]{geometry}
\usepackage{setspace}
\onehalfspacing
\usepackage{newtxtext,newtxmath}
\usepackage[dvipsnames]{xcolor} % added for link colors
\usepackage{array}
\usepackage{booktabs}
\usepackage{hyperref}            % keep after xcolor
\hypersetup{
  colorlinks=true,
  linkcolor=MidnightBlue,  % section / internal links
  urlcolor=RoyalPurple,    % URLs
  citecolor=BrickRed,      % (if you add citations later)
  filecolor=OliveGreen
}

\begin{document}

\begin{center}
  {\Large\bfseries Project Title: CareerCompass}\\[8pt]
  {\normalsize Group 85}
\end{center}

\section*{1. Team members}
\begin{itemize}
  \item Member 1: Imran Chowdhury - chowdi13@mcmaster.ca
  \item Member 2: Karim Elbasiouni — elbasik@mcmaster.ca
  \item Member 3: Rami Abu Sultan — abusultr@mcmaster.ca
\end{itemize}

\section*{2. Task title and overview}
\noindent\textbf{Title:} CareerCompass — Resume $\rightarrow$ Job Title \& Occupation Family Classification

\noindent\textbf{Overview:} Build a system that ingests a resume (PDF/DOCX/TXT or pasted text) and predicts (1) a fine-grained job title (e.g., Software Engineer, Data Analyst) and (2) a coarse occupation family (O*NET/SOC major group, e.g., Computer \& Mathematical Occupations).

\noindent\textbf{Significance:} Automated routing of candidates improves recruiter efficiency, speeds screening, and enables analytics on talent pools. 

\noindent\textbf{Challenges:} Resumes are unstructured; titles are noisy and at times synonymous (SWE vs Software Engineer II vs SDE); class imbalance; PII must be removed; hierarchical consistency between title and family must be maintained.

\section*{3. Task definition}
\noindent The project applies supervised learning to de-identified resume text converted from PDF or DOCX files, using sections such as Summary, Experience, Skills, and Education. Each resume is lightly structured through derived features that record section presence and token length, while all personally identifiable information (names, emails, addresses, phone numbers) is removed before storage.

\medskip

\noindent This dataset supports two related single-label classification tasks. The first predicts a fine-grained job title from approximately 25--30 normalized classes derived from 36 original categories (e.g., Java Developer, Data Scientist, Business Analyst). Rare or duplicate titles are merged into an Other class to reduce imbalance. The second predicts a coarse occupation family across five to seven O*NET/SOC major groups such as Computer \& Mathematical, Management, and Business Operations. Only families present in the data are used for training and evaluation.

\medskip

\noindent The model employs a shared encoder with two output heads---one for title and one for family---so that fine-grained predictions remain consistent with higher-level occupational categories. This formulation preserves interpretability, handles label noise, and maintains hierarchical structure.

\section*{4. Problem, impact, and challenges}
\subsection*{Problem Statement}
Automatically map unstructured resume text to a consistent job title and occupation family.

\medskip

\subsection*{Real-World Impact}
Large campus and new-graduate hiring cycles can produce thousands of resumes within days, so automating the first-pass routing to tracks like Software, Data/ML, or Business Analysis reduces manual screening time and improves reviewer consistency. Interpretable rationale outputs help students and recruiters understand the skill signals driving each prediction while privacy safeguards remove PII throughout the pipeline.

\medskip

\subsection*{Why It's Challenging (and how it's addressed)}
Resumes are unstructured, redundant, and imbalanced, which calls for robust text normalization, transformer-based representations, and deliberate handling of noisy formats. Title labels overlap across aliases (for example, SWE, SDE, Backend Engineer), so the system applies alias normalization and collapses rare classes. Class imbalance and hierarchical consistency are managed with weighted losses and the two-head design that links title and family predictions.

\medskip

\section*{5. Data sources and collection plan}
\textbf{Primary Dataset:} We will use is the Kaggle Resume Dataset called \href{https://www.kaggle.com/datasets/rayyankauchali0/resume-dataset?resource=download}{Resume\_Dataset} by rayyankauchali0 (CC BY 4.0).
It contains a mixture of real, synthetic and LLM-generated anonymized resumes intended for NLP research and model training. It is inspired by public sources such as \href{https://huggingface.co/collections/ahmedheakl/resumeatlas-668047e86bc332049afd0b39}{ResumeAtlas} and
\href{https://huggingface.co/datasets/datasetmaster/resumes}{datasetmaster/resumes}, both which are on HuggingFace. The author also indicates that this dataset was preprocessed for anonymization and standardization.

\noindent \textbf{Provenance \& Citation}:  We will cite the Kaggle dataset, including the author, year, URL and License, and the inspirations in SOURCES.md. We will record the download date and the checksum in DATA\_CARD.md.

\noindent \textbf{What will be done with the data?}
The following outlines the procedures we will take:
\begin{enumerate}
  \item Download dataset and record the download date and the checksum
  \item Load data and perform filter out any rows that do not have the required fields (i.e. "Experience", "Education", "Summary", "Skills")
  \item Although the author says the data is already anonymized, we will run a PII safeguard and replace any names, emails, or phone numbers with a placeholder. We will record scrubbing procedure on DATA\_CARD.md so anyone can rerun it.
  \item We will construct the following labels:
  \begin{enumerate}
    \item \textbf{Title:} Use the current/most recent job title, and normalize any aliases (Example: SDE II becomes Software Engineer). Any rare titles will be collapsed into \textbf{Other}.
    \item \textbf{Family:} Map each normalized title its O*NET/SOC 2-digit major group (23 classes total) via a lookup table.
    \item \textbf{Manual Checks:} Manually check a representative sample of resumes to ensure that the automated labelling pipeline behaves as expected. Sample can be about 100 resumes.
  \end{enumerate}
  \item We will create train/validation/test splits grouped by role cluster and source type (real,synthetic, LLM-generated etc.). From the test dataset split, we create a test subset containing only real resumes. As of now,
  data split will be 80/10/10 respectively.
  \item We will not be scraping any data or calling any APIs. All of the data would be local according to our current understanding.
\end{enumerate}

\textbf{Note:} We plan on using the entiretly of the dataset (minus any filtered out data entries). All three splits (training, validation, test) will contain mixed data, and we will have a real-only
subset of the test dataset split as mentioned above. We will report results on both the mixed and real-only test sets and compare how our model performs.\\
\textbf{DATA\_CARD.md Metadata:}
\begin{itemize}
  \item Download date and Checksum
  \item Total number of entries and total number of entries per source type
  \item PII scrub procedure
  \item List of title classes with counts
  \item Link to the title -> family lookup table
\end{itemize}

\section*{6. Expected size of the dataset and 3 example data points with labels}
 
\noindent \textbf{Planned Dataset Size:}  
3,500+ resumes total; $\geq$ 3,200 usable after minor filtering (empty Experience, malformed records). Approximately 60 normalized title classes; 23 occupation families.
 
\medskip
\noindent \textbf{Three Example (Illustrative) Records:}
 
\begin{center}
\begin{tabular}{|p{2.5cm}|p{5.5cm}|p{3.5cm}|p{3.5cm}|}
\hline
\textbf{Resume ID} & \textbf{Text Snippet} & \textbf{Title} & \textbf{Family} \\
\hline
REAL\_0001 & "...10 yrs software design \& development — senior Java developer / tech lead at Synnex (2014-Now)... REST APIs, Spring Boot...'' & Software Engineer & 15 – Computer \& Mathematical \\
REAL\_0002 & "...enthusiastic Java developer (3 yrs) — reduced app memory 30\%, startup time 70\%. Roles at DaCoderz \& Quantexx...'' & Java Developer → collapsed to Software Engineer & 15 – Computer \& Mathematical \\
REAL\_0003 & "...8 yrs delivering enterprise Java/J2EE solutions; Spring Boot, microservices, AWS; Sr Java Dev @ Fiserv (2021-Now)...'' & Senior Java Developer → collapsed to Software Engineer & 15 – Computer \& Mathematical \\
\hline
\end{tabular}
\end{center}
 
 
\section*{7. Proposed Solution}
 
\noindent \textbf{High-level Approach:}  
We plan to process resumes through text feature extraction, convert them into vector representations using TF-IDF, and use a \textbf{Linear SVM} as the baseline model for job title and occupation family classification. This baseline will help us establish performance metrics to benchmark against more advanced models.
 
\medskip
\noindent \textbf{Features / Inputs:}  
- \textbf{Text Features}:  
    - We will use \textbf{TF-IDF} to vectorize the resumes. This method captures important words in each resume, converting raw text data into numeric vectors suitable for machine learning models.
    - Additional features may include skill dictionary matches (e.g., Python, SQL, AWS), resume section presence (Summary, Experience, etc.), token counts, and average bullet length.
- \textbf{Target Labels}:  
    - \textbf{Job Title}: Fine-grained classification (e.g., Software Engineer, Data Scientist).
    - \textbf{Occupation Family}: Coarse classification (e.g., Computer \& Mathematical, Business Operations).
 
\medskip
\noindent \textbf{Baseline Model:}  
- \textbf{Linear SVM}: We will begin with a simple \textbf{Linear SVM} for both job title and occupation family classification. The model will be trained using TF-IDF vectors as features. This approach will establish baseline performance metrics (accuracy, F1 score) for evaluating future improvements.
 
\medskip
\noindent \textbf{Main Model:}  
- \textbf{DistilBERT Fine-Tuning}: After establishing baseline performance, we will fine-tune \textbf{DistilBERT} (a smaller, efficient version of BERT) to learn contextual relationships between words in resumes. This model will be evaluated using the same performance metrics, with the goal of outperforming the baseline \textbf{Linear SVM}.
 
\medskip
\noindent \textbf{Evaluation Plan:}  
- We will evaluate the models using \textbf{Top-1 accuracy} and \textbf{macro-F1 score} to handle class imbalance and ensure robust performance across all categories.
- We will also analyze the \textbf{confusion matrix} to identify where the model confuses similar job titles or occupation families.
\medskip
\noindent \textbf{Libraries / Tools:}  
- \textbf{scikit-learn} for TF-IDF vectorization and SVM implementation.
- \textbf{transformers} and \textbf{torch} for fine-tuning DistilBERT.
- \textbf{pandas} and \textbf{numpy} for data manipulation.
 
\medskip
\noindent \textbf{Existing Solutions / References:}  
- \textbf{BERT-based Models for Resume Classification}: Research shows BERT-based models excel at understanding context and improving classification performance on complex text tasks (e.g., [Devlin et al., 2019]).
- \textbf{Multi-class Text Classification}: Previous work has used models like SVM with TF-IDF for text classification tasks, including document categorization (e.g., [Joachims, 1998]).
- \textbf{Hierarchical Classification for Job Titles}: Several approaches explore hierarchical relationships in job title classification (e.g., [Vaswani et al., 2017]).
§4 for details.

\end{document}
