\documentclass[12pt]{article}
\usepackage[margin=0.8in]{geometry}
\usepackage{setspace}
\onehalfspacing
\usepackage{newtxtext,newtxmath}
\usepackage[dvipsnames]{xcolor} % added for link colors
\usepackage{array}
\usepackage{booktabs}
\usepackage{hyperref}            % keep after xcolor
\hypersetup{
  colorlinks=true,
  linkcolor=MidnightBlue,  % section / internal links
  urlcolor=RoyalPurple,    % URLs
  citecolor=BrickRed,      % (if you add citations later)
  filecolor=OliveGreen
}

\begin{document}

\begin{center}
  {\Large\bfseries Project Title: CareerCompass}\\[8pt]
  {\normalsize Group 85}
\end{center}

\section*{1. Team members}
\begin{itemize}
  \item Member 1: Imran Chowdhury - chowdi13@mcmaster.ca
  \item Member 2: Karim Elbasiouni — elbasik@mcmaster.ca
  \item Member 3: Rami Abu Sultan — abusultr@mcmaster.ca
\end{itemize}

\section*{2. Task title and overview}
\noindent\textbf{Title:} CareerCompass — Resume $\rightarrow$ Job Title \& Occupation Family Classification

\noindent\textbf{Overview:} Build a system that ingests a resume (PDF/DOCX/TXT or pasted text) and predicts (1) a fine-grained job title (e.g., Software Engineer, Data Analyst) and (2) a coarse occupation family (O*NET/SOC major group, e.g., Computer \& Mathematical Occupations).

\noindent\textbf{Significance:} Automated routing of candidates improves recruiter efficiency, speeds screening, and enables analytics on talent pools. 

\noindent\textbf{Challenges:} Resumes are unstructured; titles are noisy and at times synonymous (SWE vs Software Engineer II vs SDE); class imbalance; PII must be removed; hierarchical consistency between title and family must be maintained.

\section*{3. Task definition}
\noindent The project applies supervised learning to de-identified resume text converted from PDF or DOCX files, using sections such as Summary, Experience, Skills, and Education. Each resume is lightly structured through derived features that record section presence and token length, while all personally identifiable information (names, emails, addresses, phone numbers) is removed before storage.

\medskip

\noindent This dataset supports two related single-label classification tasks. The first predicts a fine-grained job title from approximately 25--30 normalized classes derived from 36 original categories (e.g., Java Developer, Data Scientist, Business Analyst). Rare or duplicate titles are merged into an Other class to reduce imbalance. The second predicts a coarse occupation family across five to seven O*NET/SOC major groups such as Computer \& Mathematical, Management, and Business Operations. Only families present in the data are used for training and evaluation.

\medskip

\noindent The model employs a shared encoder with two output heads---one for title and one for family---so that fine-grained predictions remain consistent with higher-level occupational categories. This formulation preserves interpretability, handles label noise, and maintains hierarchical structure.

\section*{4. Problem, impact, and challenges}
\subsection*{Problem Statement}
Automatically map unstructured resume text to a consistent job title and occupation family.

\medskip

\subsection*{Real-World Impact}
Large campus and new-graduate hiring cycles can produce thousands of resumes within days, so automating the first-pass routing to tracks like Software, Data/ML, or Business Analysis reduces manual screening time and improves reviewer consistency. Interpretable rationale outputs help students and recruiters understand the skill signals driving each prediction while privacy safeguards remove PII throughout the pipeline.

\medskip

\subsection*{Why It’s Challenging (and how it’s addressed)}
Resumes are unstructured, redundant, and imbalanced, which calls for robust text normalization, transformer-based representations, and deliberate handling of noisy formats. Title labels overlap across aliases (for example, SWE, SDE, Backend Engineer), so the system applies alias normalization and collapses rare classes. Class imbalance and hierarchical consistency are managed with weighted losses and the two-head design that links title and family predictions.

\medskip

\section*{5. Data sources and collection plan}
\textbf{Primary Dataset:} We will use is the Kaggle Resume Dataset called \href{https://www.kaggle.com/datasets/rayyankauchali0/resume-dataset?resource=download}{Resume\_Dataset} by rayyankauchali0 (CC BY 4.0).
It contains a mixture of real, synthetic and LLM-generated anonymized resumes intended for NLP research and model training. It is inspired by public sources such as \href{https://huggingface.co/collections/ahmedheakl/resumeatlas-668047e86bc332049afd0b39}{ResumeAtlas} and
\href{https://huggingface.co/datasets/datasetmaster/resumes}{datasetmaster/resumes}, both which are on HuggingFace. The author also indicates that this dataset was preprocessed for anonymization and standardization.

\noindent \textbf{Provenance \& Citation}:  We will cite the Kaggle dataset, including the author, year, URL and License, and the inspirations in SOURCES.md. We will record the download date and the checksum in DATA\_CARD.md.

\noindent \textbf{What will be done with the data?}
The following outlines the procedures we will take:
\begin{enumerate}
  \item Download dataset and record the download date and the checksum
  \item Load data and perform filter out any rows that do not have the required fields (i.e. "Experience", "Education", "Summary", "Skills")
  \item Although the author says the data is already anonymized, we will run a PII safeguard and replace any names, emails, or phone numbers with a placeholder. We will record scrubbing procedure on DATA\_CARD.md so anyone can rerun it.
  \item We will construct the following labels:
  \begin{enumerate}
    \item \textbf{Title:} Use the current/most recent job title, and normalize any aliases (Example: SDE II becomes Software Engineer). Any rare titles will be collapsed into \textbf{Other}.
    \item \textbf{Family:} Map each normalized title its O*NET/SOC 2-digit major group (23 classes total) via a lookup table.
    \item \textbf{Manual Checks:} Manually check a representative sample of resumes to ensure that the automated labelling pipeline behaves as expected. Sample can be about 100 resumes.
  \end{enumerate}
  \item We will create train/validation/test splits grouped by role cluster and source type (real,synthetic, LLM-generated etc.). From the test dataset split, we create a test subset containing only real resumes. As of now,
  data split will be 80/10/10 respectively.
  \item We will not be scraping any data or calling any APIs. All of the data would be local according to our current understanding.
\end{enumerate}

\textbf{Note:} We plan on using the entiretly of the dataset (minus any filtered out data entries). All three splits (training, validation, test) will contain mixed data, and we will have a real-only
subset of the test dataset split as mentioned above. We will report results on both the mixed and real-only test sets and compare how our model performs.\\
\textbf{DATA\_CARD.md Metadata:}
\begin{itemize}
  \item Download date and Checksum
  \item Total number of entries and total number of entries per source type
  \item PII scrub procedure
  \item List of title classes with counts
  \item Link to the title -> family lookup table
\end{itemize}



1 Overview
For the course project, you will gain experience with building a fully functional machine learning ap-
plication. You get to come up with this project with your teammates, however, this project should
be non-trivial, and have significant effort in some combination of the data collection techniques,
modeling approach, and evaluation strategy. You may not directly replicate existing projects.
2 Proposal
The first milestone is to complete your project proposal. The format of the proposal will be a PDF
document which includes the following items:
1. Team members (2-3 people required)
2. Task title and overview, including the significance and what makes it challenging
3. Task definition (type of data, classification/regression/generation, number of classes, single
label or multi-label)
4. Describe the problem, it’s impact on the real world, and why it is challenging.
5. Data source(s) and plan for data collection. This may include how you are going to scrape the
data and follow terms-of-service, API access and handling rate limiting, using open-source
data, or any other relevant details. If your data does not have labels, how do you plan to
get them? If assigning labels by hand, how long does it take per instance? Include links to
the data if relevant. If you download your dataset from Kaggle, you must include the Kaggle
link and the original data source link from where the dataset was downloaded and posted on
Kaggle. Include any meta-data available for your corpus. If you are not collecting it yourself,
include details about how the data was collected, annotated, preprocessed, etc. Do not work
on the datasets for which no source information is available. Please indicate whether you will
use a small subset of the data or features for your project or the entire dataset, and why.
6. Expected size of the dataset (number of data points) and 3 example data points with labels.
Your dataset should have at least 1k data points. Some projects will have more or less data.
7. Proposed solution: How do you plan to go about solving this problem? It is okay to not know
how the machine learning models work at this point in the class, but you should be starting
to get some idea based on the lectures and assigned readings. What kind of features and
target labels do you have? What kind of models might you try? You may not propose simple
linear regression models for this project. Are there any existing solutions to your problem?
You must indicate 2-5 sources (research papers, books, machine learning challenges online)
from where your solution was inspired. Put some thought into how you would approach this.
How will you know if the model is good? How will you evaluate it? Also, share the libraries
you intend to use for the project.
8. A team contract signed by all team members. This is a description of the expectations
and/or roles that team members agree upon for the semester. Part of your final project grade
will be based on whether your teammates agree that you followed this contract. See section
§4 for details.

\end{document}
