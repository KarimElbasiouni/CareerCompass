\documentclass[12pt]{article}
\usepackage[margin=0.8in]{geometry}
\usepackage{setspace}
\onehalfspacing
\usepackage{newtxtext,newtxmath}
\usepackage[dvipsnames]{xcolor} % added for link colors
\usepackage{array}
\usepackage{booktabs}
\usepackage{hyperref}            % keep after xcolor
\hypersetup{
  colorlinks=true,
  linkcolor=MidnightBlue,  % section / internal links
  urlcolor=RoyalPurple,    % URLs
  citecolor=BrickRed,      % (if you add citations later)
  filecolor=OliveGreen
}

\begin{document}

\begin{center}
  {\Large\bfseries Project Title: CareerCompass}\\[8pt]
  {\normalsize Group 85}
\end{center}

\section*{1. Team members}
\begin{itemize}
  \item Member 1: Imran Chowdhury - chowdi13@mcmaster.ca
  \item Member 2: Karim Elbasiouni — elbasik@mcmaster.ca
  \item Member 3: Rami Abu Sultan — abusultr@mcmaster.ca
\end{itemize}

\section*{2. Task title and overview}
\noindent\textbf{Title:} CareerCompass — Resume $\rightarrow$ Job Title \& Occupation Family Classification

\noindent\textbf{Overview:} Build a system that ingests a resume (PDF/DOCX/TXT or pasted text) and predicts (1) a fine-grained job title (e.g., Software Engineer, Data Analyst) and (2) a coarse occupation family (O*NET/SOC major group, e.g., Computer \& Mathematical Occupations).

\noindent\textbf{Significance:} Automated routing of candidates improves recruiter efficiency, speeds screening, and enables analytics on talent pools. 

\noindent\textbf{Challenges:} Resumes are unstructured; titles are noisy and at times synonymous (SWE vs Software Engineer II vs SDE); class imbalance; PII must be removed; hierarchical consistency between title and family must be maintained.

\section*{3. Task definition}
\noindent The project applies supervised learning to de-identified resume text converted from PDF or DOCX files, using sections such as Summary, Experience, Skills, and Education. Each resume is lightly structured through derived features that record section presence and token length, while all personally identifiable information (names, emails, addresses, phone numbers) is removed before storage.

\medskip

\noindent This dataset supports two related single-label classification tasks. The first predicts a fine-grained job title from approximately 25--30 normalized classes derived from 36 original categories (e.g., Java Developer, Data Scientist, Business Analyst). Rare or duplicate titles are merged into an Other class to reduce imbalance. The second predicts a coarse occupation family across five to seven O*NET/SOC major groups such as Computer \& Mathematical, Management, and Business Operations. Only families present in the data are used for training and evaluation.

\medskip

\noindent The model employs a shared encoder with two output heads---one for title and one for family---so that fine-grained predictions remain consistent with higher-level occupational categories. This formulation preserves interpretability, handles label noise, and maintains hierarchical structure.

\section*{4. Problem, impact, and challenges}
\subsection*{Problem Statement}
Automatically map unstructured resume text to a consistent job title and occupation family.

\medskip

\subsection*{Real-World Impact}
Large campus and new-graduate hiring cycles can produce thousands of resumes within days, so automating the first-pass routing to tracks like Software, Data/ML, or Business Analysis reduces manual screening time and improves reviewer consistency. Interpretable rationale outputs help students and recruiters understand the skill signals driving each prediction while privacy safeguards remove PII throughout the pipeline.

\medskip

\subsection*{Why It’s Challenging (and how it’s addressed)}
Resumes are unstructured, redundant, and imbalanced, which calls for robust text normalization, transformer-based representations, and deliberate handling of noisy formats. Title labels overlap across aliases (for example, SWE, SDE, Backend Engineer), so the system applies alias normalization and collapses rare classes. Class imbalance and hierarchical consistency are managed with weighted losses and the two-head design that links title and family predictions.

\medskip

\section*{5. Data sources and collection plan}
\textbf{Primary Dataset:} We will use is the Kaggle Resume Dataset called \href{https://www.kaggle.com/datasets/rayyankauchali0/resume-dataset?resource=download}{Resume\_Dataset} by rayyankauchali0 (CC BY 4.0).
It contains a mixture of real, synthetic and LLM-generated anonymized resumes intended for NLP research and model training. It is inspired by public sources such as \href{https://huggingface.co/collections/ahmedheakl/resumeatlas-668047e86bc332049afd0b39}{ResumeAtlas} and
\href{https://huggingface.co/datasets/datasetmaster/resumes}{datasetmaster/resumes}, both which are on HuggingFace. The author also indicates that this dataset was preprocessed for anonymization and standardization.

\noindent \textbf{Provenance \& Citation}:  We will cite the Kaggle dataset, including the author, year, URL and License, and the inspirations in SOURCES.md. We will record the download date and the checksum in DATA\_CARD.md.

\noindent \textbf{What will be done with the data?}
The following outlines the procedures we will take:
\begin{enumerate}
  \item Download dataset and record the download date and the checksum
  \item Load data and perform filter out any rows that do not have the required fields (i.e. "Experience", "Education", "Summary", "Skills")
  \item Although the author says the data is already anonymized, we will run a PII safeguard and replace any names, emails, or phone numbers with a placeholder. We will record scrubbing procedure on DATA\_CARD.md so anyone can rerun it.
  \item We will construct the following labels:
  \begin{enumerate}
    \item \textbf{Title:} Use the current/most recent job title, and normalize any aliases (Example: SDE II becomes Software Engineer). Any rare titles will be collapsed into \textbf{Other}.
    \item \textbf{Family:} Map each normalized title its O*NET/SOC 2-digit major group (23 classes total) via a lookup table.
    \item \textbf{Manual Checks:} Manually check a representative sample of resumes to ensure that the automated labelling pipeline behaves as expected. Sample can be about 100 resumes.
  \end{enumerate}
  \item We will create train/validation/test splits grouped by role cluster and source type (real,synthetic, LLM-generated etc.). From the test dataset split, we create a test subset containing only real resumes. As of now,
  data split will be 80/10/10 respectively.
  \item We will not be scraping any data or calling any APIs. All of the data would be local according to our current understanding.
\end{enumerate}

\textbf{Note:} We plan on using the entiretly of the dataset (minus any filtered out data entries). All three splits (training, validation, test) will contain mixed data, and we will have a real-only
subset of the test dataset split as mentioned above. We will report results on both the mixed and real-only test sets and compare how our model performs.\\
\textbf{DATA\_CARD.md Metadata:}
\begin{itemize}
  \item Download date and Checksum
  \item Total number of entries and total number of entries per source type
  \item PII scrub procedure
  \item List of title classes with counts
  \item Link to the title -> family lookup table
\end{itemize}


\section*{6. Expected dataset size and example datapoints}
\textbf{Expected size:} 3,500+ resumes total; $\geq$3,200 usable after filtering. \\
Fine-grained titles: ~60 classes, Occupation families: 23 classes

\textbf{Three example records:} \\[2pt]
\begin{tabular}{p{0.62\linewidth} p{0.32\linewidth}}
\toprule
Text snippet (input) & Label(s) \\
\midrule
"...10 yrs software design \& development -- senior Java developer / tech lead at Synnex (2014-Now)... REST APIs, Spring Boot..." & Software Engineer / Computer \& Mathematical \\
"...enthusiastic Java developer (3 yrs) -- reduced app memory 30\%, startup time 70\%. Roles at DaCoderz \& Quantexx..." & Java Developer / Computer \& Mathematical \\
"...8 yrs delivering enterprise Java/J2EE solutions; Spring Boot, microservices, AWS; Sr Java Dev @ Fiserv (2021-Now)..." & Software Engineer / Computer \& Mathematical \\
\bottomrule
\end{tabular}

\section*{7. Proposed solution}
\textbf{High-level approach:} Resume $\rightarrow$ preprocessing $\rightarrow$ feature extraction $\rightarrow$ two-head classifier (title + family) $\rightarrow$ evaluation and interpretation

\textbf{Features / inputs:}
\begin{itemize}
  \item Text features: normalized text (Experience $\rightarrow$ Skills $\rightarrow$ Summary/Education), TF-IDF vectors, or embeddings (DistilBERT / Sentence-BERT)
  \item Structured features: section flags, token counts, average bullet length, skill dictionary hits (Python, SQL, AWS, Kubernetes, Terraform)
\end{itemize}

\textbf{Model candidates:}
\begin{itemize}
  \item Baseline: Linear SVM, LightGBM
  \item Advanced: DistilBERT / Sentence-BERT two-head multi-task classifier
  \item Handle class imbalance with class weights/focal loss; collapse rare titles into Other
\end{itemize}

\textbf{Evaluation plan:}
\begin{itemize}
  \item Job title: Top-1 / Top-3 accuracy, macro-F1, confusion analysis
  \item Occupation family: accuracy + hierarchical correctness
  \item Calibration: Brier score, reliability curves
  \item Robustness: real-only vs mixed test, short vs long resumes
  \item Fairness: slices based on resume length and section presence
\end{itemize}

\textbf{Interpretability:}
\begin{itemize}
  \item Baseline: SHAP on n-grams and skill features
  \item Transformer: token-level attention highlights + short rationale
\end{itemize}

\textbf{Libraries / tools:}
\begin{itemize}
  \item pandas, numpy, scikit-learn, LightGBM
  \item transformers, sentence-transformers, torch
  \item shap, spaCy, pdfminer.six, python-docx
\end{itemize}

\textbf{Related work / references (2--5 sources):}
\begin{itemize}
  \item Multi-class text classification with TF-IDF + SVM/GBDT
  \item BERT fine-tuning for document classification with multi-task heads
  \item Hierarchical evaluation (family-level correctness when title is ambiguous)
  \item Industry practices for resume/job normalization using skill dictionaries
\end{itemize}

\end{document}
